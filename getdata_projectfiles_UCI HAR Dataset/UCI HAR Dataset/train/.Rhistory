install.packages("httr")
require(RCurl)
require(XML)
webpage <- getURL("http://www.adkbyowner.com/listings/VR5626.html")
webpage <- readLines(tc <- textConnection(webpage)); close(tc)
pagetree <- htmlTreeParse(webpage, error=function(...){}, useInternalNodes = TRUE)
# parse the tree by tables
x <- xpathSApply(pagetree, "//*/table", xmlValue)
# do some clean up with regular expressions
x <- unlist(strsplit(x, "\n"))
x <- gsub("\t","",x)
x <- sub("^[[:space:]]*(.*?)[[:space:]]*$", "\\1", x, perl=TRUE)
x <- x[!(x %in% c("", "|"))]
x <- data.table(x)
library(data.table)
library(dplyr)
x <- data.table(x)
head(x)
x
library(data.table)
library(dplyr)
require(RCurl)
require(XML)
webpage <- getURL("http://www.baseball-reference.com/players/gl.cgi?id=wrighda03&t=b&year=2014")
webpage <- readLines(tc <- textConnection(webpage)); close(tc)
pagetree <- htmlTreeParse(webpage, error=function(...){}, useInternalNodes = TRUE)
# parse the tree by tables
x <- xpathSApply(pagetree, "//*/table", xmlValue)
# do some clean up with regular expressions
x <- unlist(strsplit(x, "\n"))
x <- gsub("\t","",x)
x <- sub("^[[:space:]]*(.*?)[[:space:]]*$", "\\1", x, perl=TRUE)
x <- x[!(x %in% c("", "|"))]
x <- data.table(x)
head(x)
str(x)
View(x)
library(httr)
library(dplyr)
require(RCurl)
require(XML)
webpage <- getURL("http://www.baseball-reference.com/players/gl.cgi?id=wrighda03&t=b&year=2014")
webpage <- readLines(tc <- textConnection(webpage)); close(tc)
pagetree <- htmlTreeParse(webpage, error=function(...){}, useInternalNodes = TRUE)
# parse the tree by tables
x <- xpathSApply(pagetree, "//*/table", xmlValue)
# do some clean up with regular expressions
x <- unlist(strsplit(x, "\n"))
x <- gsub("\t","",x)
x <- sub("^[[:space:]]*(.*?)[[:space:]]*$", "\\1", x, perl=TRUE)
x <- x[!(x %in% c("", "|"))]
head(x)
str(x)
View(x)
con = url("http://www.baseball-reference.com/players/w/wrighda03.shtml")
htmlCode = readLines(con)
close(con)
htmlCode
df <- read.fwf(
file=url("http://www.cpc.ncep.noaa.gov/data/indices/wksst8110.for"),
widths=c(-1,9,-5,4,4,-5,4,4,-5,4,4,-5,4,4),
skip=4
)
head(df)
sum(df$V4)
df <- read.fwf(
file=url("
https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for"),
widths=c(-1,9,-5,4,4,-5,4,4,-5,4,4,-5,4,4),
skip=4
)
df <- read.fwf(
file=url("
http://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for"),
widths=c(-1,9,-5,4,4,-5,4,4,-5,4,4,-5,4,4),
skip=4
)
df <- read.fwf(
file=url("
http://www.cpc.ncep.noaa.gov/data/indices/wksst8110.for"),
widths=c(-1,9,-5,4,4,-5,4,4,-5,4,4,-5,4,4),
skip=4
)
df <- read.fwf(
file=url("http://www.cpc.ncep.noaa.gov/data/indices/wksst8110.for"),
widths=c(-1,9,-5,4,4,-5,4,4,-5,4,4,-5,4,4),
skip=4
)
library(data.table)
data.table(df)
x <- data.table(df)
x <- select(df, V4)
library(dplyr)
x <- select(df, V4)
sum(x)
df <- read.fwf(
file=url("http://www.cpc.ncep.noaa.gov/data/indices/wksst8110.for"),
widths=c(-1,9,-5,4,4,-5,4,4,-5,4,4,-5,4,4),
skip=4
)
x <- data.table(df)
x <- select(df, V4)
sum(x)
x <- read.fwf(
file=url("http://www.cpc.ncep.noaa.gov/data/indices/wksst8110.for"),
skip=4,
widths=c(12, 7,4, 9,4, 9,4, 9,4))
sum(df$V4)
colClasses(df)
x <- read.fwf(
file=url("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for"), header= F,
skip=4,
widths=c(12, 7,4, 9,4, 9,4, 9,4))
sum(df$V4)
sum(x$V4)
library(lattice)
install.packages("ggplot2")
library(nlme)
library(lattice)
xyplot(weight ~ Time | Diet, BodyWeight)
library(nlme)
library(lattice)
xyplot(weight ~ Time | Diet, BodyWeight)
library(ggplot2)
qplot(votes, rating, data = movies)
qplot(votes, rating, data = movies) + geom_smooth()
qplot(votes, rating, data = movies, smooth = "loess")
qplot(votes, rating, data = movies, panel = panel.loess)
qplot(votes, rating, data = movies) + stats_smooth("loess")
x <- qplot(votes, rating, data = movies)
x + geom_smooth()
qplot(votes, rating, data = movies) + stats_smooth("loess")
qplot(votes, rating, data = movies, panel = panel.loess)
qplot(votes, rating, data = movies, smooth = "loess")
head(movies)
?trellis.par.set
?par
library(swirl)
swirl()
library(tidyr)
students
gather(students)
?gather
gather(students, sex, count, -grade)
students2
bye(*)
bye()
library(swirl)
swirl()
library(tidyr)
res <- gather(students2, sex_class, count, -grade)
res
?separate
separate(res, sex_class, into = c("sex", "class"))
students2 %>%
gather(sex_class , count, -grade) %>%
separate( , c("sex", "class")) %>%
print
submit()
submit()
reset()
submit()
submit()
students3
submit()
submit()
submit()
submit()
submit()
submit()
submit()
submit()
submit()
submit()
submit()
submit()
submit()
submit()
submit()
?spread
submit()
submit()
submit()
reset()
submit()
swirl()
library(dplyr)
stocks <- data.frame(
time = as.Date('2009-01-01') + 0:9,
X = rnorm(10, 0, 1),
Y = rnorm(10, 0, 2),
Z = rnorm(10, 0, 4)
)
stocks
stocksm <- stocks %>% gather(stock, price, -time)
stocksm
stocksm %>% spread(stock, price)
swirl()
submit()
extract_numeric("class5")
?mutate
submit()
submit()
submit()
submit()
submit()
submit()
students4
submit()
submit()
submit()
submit()
submit()
passed
failed
mutate(passed, status = "passed")
passed <- mutate(passed, status = "passed")
failed <- mutate(failed, status = "failed")
packageVersion('dplyr')
?bind_rows
bind_rows(passed, failed)
sat
submit()
submit()
submit()
submit()
setwd("//MYBOOKLIVE/mlutz/Coursera/GettingandCleaningData/data")
setwd("//MYBOOKLIVE/mlutz/Coursera/GettingandCleaningData")
setwd("//MYBOOKLIVE/mlutz/Coursera/GettingandCleaningData/getdata_projectfiles_UCI HAR Dataset")
setwd("//MYBOOKLIVE/mlutz/Coursera/GettingandCleaningData/getdata_projectfiles_UCI HAR Dataset/UCI HAR Dataset/train")
trainlabels <- read.table("test/y_train")
trainlabels <- read.table("test/y_train.txt")
trainlabels <- read.table(test/y_train.txt)
trainlabels <- read.table(test\y_train.txt)
trainlabels <- read.table("y_train.txt")
dim(trainlabels)
train <- read.table("X_train.txt")
?cbind
train2 <- cbind(trainlabels, train)
head(train2)
library(dplyr)
